{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1c0682",
   "metadata": {},
   "source": [
    "Carregando os pacotes necessários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7881ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "import numpy as np\n",
    "\n",
    "import flwr as fl\n",
    "import pandas as pd\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e512c0c",
   "metadata": {},
   "source": [
    "Carregando o dataset CIFAR-10 (conjuntos de treinamento e teste):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80bba05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    trainset = CIFAR10(\".\", train = True, download = True, transform = transform)\n",
    "    testset = CIFAR10(\".\", train = False, download = True, transform = transform)\n",
    "    trainloader = DataLoader(trainset, batch_size = 8, shuffle = True)\n",
    "    testloader = DataLoader(testset, batch_size = 8)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea1f313",
   "metadata": {},
   "source": [
    "### Redes Neurais\n",
    "\n",
    "Modelo 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7398c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3,\n",
    "                               padding = 1, \n",
    "                               stride = 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3,\n",
    "                               padding = 1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3,\n",
    "                               padding = 1)\n",
    "        self.conv4 = nn.Conv2d(256, 512, 3,\n",
    "                               padding = 1)\n",
    "        self.fc1 = nn.Linear(256, 10)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features = 256)\n",
    "        #self.bn2 = nn.BatchNorm2d(num_features = 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.bn1(self.conv3(x))))\n",
    "        #x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 256)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7656835",
   "metadata": {},
   "source": [
    "Modelo 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be66072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"Simple CNN adapted\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(12544, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4162e68e",
   "metadata": {},
   "source": [
    "Função de treinamento da rede:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6316406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #criterion = NoPeekLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training {epochs} epoch(s) w/ {len(trainloader)} mini-batches each\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print()\n",
    "        loss_epoch: float = 0.0\n",
    "        correct: float = 0.0\n",
    "        num_examples_train: int = 0\n",
    "        batch_idx: int = 0\n",
    "        total: int = 0\n",
    "            \n",
    "        for images, labels in trainloader:\n",
    "            \n",
    "            if batch_idx < len(trainloader)-1:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "                num_examples_train += len(images)\n",
    "                batch_idx += 1\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                loss = criterion(outputs, labels)   \n",
    "                #intermediate_parameters = []\n",
    "                #for param in net.parameters():\n",
    "                #    intermediate_parameters.append(param.view(-1))\n",
    "                #intermediate_parameters = torch.cat(intermediate_parameters)                    \n",
    "                #loss = criterion(images, intermediate_parameters, net(images), labels).item() \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_epoch += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                if batch_idx % 10 == 8:\n",
    "                    print(\n",
    "                        \"Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f}\\t\\t\\t\\t\\t\\t\\t\\t\".format(\n",
    "                            epoch,\n",
    "                            num_examples_train,\n",
    "                            len(trainloader) * trainloader.batch_size,\n",
    "                            100.0\n",
    "                            * num_examples_train\n",
    "                            / len(trainloader)\n",
    "                            / trainloader.batch_size,\n",
    "                            loss.item(),\n",
    "                        ),\n",
    "                        end=\"\\r\",\n",
    "                        flush=True,\n",
    "                    )\n",
    "            \n",
    "        loss_train.append(loss.item())\n",
    "        acc_train.append(correct / total    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd45d0b",
   "metadata": {},
   "source": [
    "Definindo a função de teste do servidor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3e4fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #criterion = NoPeekLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()    \n",
    "            #intermediate_parameters = []\n",
    "            #for param in net.parameters():\n",
    "            #    intermediate_parameters.append(param.view(-1))\n",
    "            #intermediate_parameters = torch.cat(intermediate_parameters)\n",
    "            #loss += criterion(images, intermediate_parameters, outputs, labels).item()    \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total    \n",
    "    acc_test.append(accuracy)\n",
    "    loss_test.append(loss/len(testloader))\n",
    "    return loss/len(testloader), accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43004bb",
   "metadata": {},
   "source": [
    "Definindo a função cliente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89e736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "class CifarClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, train_loader, test_loader, epochs, device: torch.device = torch.device(DEVICE)):\n",
    "        self.model = CNN().to(device)   \n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in zip(self.model.state_dict().keys(), weights)})\n",
    "        self.model.load_state_dict(state_dict, strict = True)\n",
    "        \n",
    "    def get_parameters(self) -> fl.common.Weights:\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        #intermediate_parameters  = self.get_weights()\n",
    "        train(self.model, self.train_loader, epochs = self.epochs)\n",
    "        return self.get_parameters(), len(self.train_loader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):        \n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = test(self.model, self.test_loader)   \n",
    "        return float(loss), len(self.test_loader), {\"accuracy\":float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a70d6",
   "metadata": {},
   "source": [
    "Executando o servidor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f4361c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2021-08-19 00:35:35,280 | connection.py:36 | ChannelConnectivity.IDLE\n",
      "INFO flower 2021-08-19 00:35:35,281 | app.py:61 | Opened (insecure) gRPC connection\n",
      "DEBUG flower 2021-08-19 00:35:35,281 | connection.py:36 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 10 epoch(s) w/ 6250 mini-batches each\n",
      "\n",
      "Train Epoch: 0 [304/50000 (1%)] Loss: 2.360018\t\t\t\t\t\t\t\t\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduarda/cybersecurity/Cybersecurity-FL/env/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [49984/50000 (100%)] Loss: 1.073846\t\t\t\t\t\t\t\t\n",
      "Train Epoch: 1 [49984/50000 (100%)] Loss: 1.348539\t\t\t\t\t\t\t\t\n",
      "Train Epoch: 2 [49984/50000 (100%)] Loss: 1.166071\t\t\t\t\t\t\t\t\n",
      "Train Epoch: 3 [49984/50000 (100%)] Loss: 1.499974\t\t\t\t\t\t\t\t\n",
      "Train Epoch: 4 [49984/50000 (100%)] Loss: 1.349347\t\t\t\t\t\t\t\t\n",
      "Train Epoch: 5 [49984/50000 (100%)] Loss: 1.375231\t\t\t\t\t\t\t\t\n",
      "Train Epoch: 6 [49984/50000 (100%)] Loss: 0.690024\t\t\t\t\t\t\t\t\n",
      "Train Epoch: 7 [49984/50000 (100%)] Loss: 0.610929\t\t\t\t\t\t\t\t\n",
      "Train Epoch: 8 [49984/50000 (100%)] Loss: 0.532330\t\t\t\t\t\t\t\t\n",
      "Train Epoch: 9 [49984/50000 (100%)] Loss: 1.342224\t\t\t\t\t\t\t\t\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2021-08-19 00:41:37,703 | connection.py:68 | Insecure gRPC channel closed\n",
      "INFO flower 2021-08-19 00:41:37,704 | app.py:72 | Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "current_client = 1\n",
    "n_clients = 2\n",
    "train_batch_size = 32\n",
    "test_batch_size = 1000\n",
    "epochs = 10\n",
    "\n",
    "train_loader, test_loader = load_data()\n",
    "\n",
    "df = pd.DataFrame(list())\n",
    "df.to_csv('accuracy_1.csv')\n",
    "df.to_csv('loss_1.csv')\n",
    "\n",
    "client = CifarClient(\n",
    "        cid = current_client,\n",
    "        train_loader = train_loader,\n",
    "        test_loader = test_loader,\n",
    "        epochs = epochs,\n",
    "        device = DEVICE,\n",
    ")\n",
    "\n",
    "fl.client.start_numpy_client(\"[::]:8081\", client = client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb51260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test [0.6213]\n",
      "Loss Train [1.650738000869751, 1.6103835105895996, 0.7185038924217224, 0.8863129615783691, 0.7790144085884094, 0.6811245083808899, 1.0082215070724487, 0.9230215549468994, 1.0828007459640503, 1.1398513317108154]\n",
      "Loss Test [1.0870145292401314]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Test\", acc_test)\n",
    "print(\"Loss Train\", loss_train)\n",
    "print(\"Loss Test\", loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ab72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
