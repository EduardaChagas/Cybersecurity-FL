{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fe5256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import flwr as fl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae8dd6",
   "metadata": {},
   "source": [
    "### Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d364b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    transform = transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "                ])\n",
    "    \n",
    "    trainset = MNIST(root = './data', \n",
    "                     train = True, \n",
    "                     transform = transform, \n",
    "                     download = True)\n",
    "    testset = MNIST(root = './data', \n",
    "                    train = False, \n",
    "                    transform = transform, \n",
    "                    download = True)\n",
    "\n",
    "    victim_idx = random.sample(range(trainset.data.shape[0]), k=2000) # seleciona quais dados vão ser passados para o cliente\n",
    "    victim_train_idx = victim_idx[:1000] # seleciona os 1000 primeiros dados para treinamento \n",
    "    attack_idx = victim_idx[1000:] # a segunda metade dos dados será destinada ao atacante\n",
    "    victim_test_idx = random.sample(range(testset.data.shape[0]), k=15) # seleciona 15 dados para o teste\n",
    "\n",
    "    victim_train_dataset = Subset(trainset, victim_train_idx)\n",
    "    attack_dataset = Subset(trainset, attack_idx)\n",
    "    victim_test_dataset = Subset(testset, victim_test_idx)\n",
    "\n",
    "    victim_train_dataloader = torch.utils.data.DataLoader(victim_train_dataset, \n",
    "                                                          batch_size = 64, \n",
    "                                                          shuffle = True)\n",
    "    attack_dataloader = torch.utils.data.DataLoader(attack_dataset, \n",
    "                                                    batch_size = 64, \n",
    "                                                    shuffle = True)\n",
    "    victim_test_dataloader = torch.utils.data.DataLoader(victim_test_dataset, \n",
    "                                                         batch_size = 64, \n",
    "                                                         shuffle = False)\n",
    "    \n",
    "    return victim_train_dataloader, victim_test_dataloader, attack_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "896c33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_train_dataloader, victim_test_dataloader, attack_dataloader = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b2aeb6",
   "metadata": {},
   "source": [
    "### Funções de treinamento e teste do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2849a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, victim_train_dataloader, epochs):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = NoPeekLoss(alpha = 0.8)\n",
    "    optimizer = optim.Adam(net.parameters(), lr = 1e-3)\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for images, labels in victim_train_dataloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "038dbabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, victim_test_dataloader):\n",
    "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "    criterion = NoPeekLoss(alpha = 0.8) #Analisar como vai ficar o criterio\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in victim_test_dataloader:\n",
    "            images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e9e8e",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f357395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoPeekFL(nn.Module):\n",
    "    \"\"\"Model for MNIST Classification.\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super(NoPeekFL, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, \n",
    "                               out_channels = 64,\n",
    "                               kernel_size = 3, \n",
    "                               padding = 1, \n",
    "                               stride = 1)        \n",
    "        self.conv2 = nn.Conv2d(in_channels = 64, \n",
    "                               out_channels = 128,\n",
    "                               kernel_size = 3, \n",
    "                               padding = 1)        \n",
    "        self.conv3 = nn.Conv2d(in_channels = 128, \n",
    "                               out_channels = 256,\n",
    "                               kernel_size = 3, \n",
    "                               padding = 1)        \n",
    "        self.conv4 = nn.Conv2d(in_channels = 256, \n",
    "                               out_channels = 512,\n",
    "                               kernel_size = 3, \n",
    "                               padding = 1)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.L1 = nn.Linear(512, 10) # Temos 10 classes\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # 3ch > 64ch, shape 32 x 32 -> 16 x 16\n",
    "        x = self.conv1(x) # [64,32,32]\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2) # [64,16,16]\n",
    "        \n",
    "        # 64ch > 128ch, shape 16 x 16 -> 8 x 8\n",
    "        x = self.conv2(x) # [128,16,16]\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2) # [128,8,8]\n",
    "        \n",
    "        x = self.conv3(x) # [256,8,8]\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2) # [256,4,4]   \n",
    "\n",
    "        # 256ch > 512ch, shape 4 x 4 -> 2 x 2\n",
    "        x = self.conv4(x) # [512,4,4]\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2) # [512,2,2]\n",
    "        \n",
    "        # camada totalmente conectada\n",
    "        x = x.view(-1, 512)\n",
    "        x = self.L1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dd4a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NoPeekFL()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0fca61",
   "metadata": {},
   "source": [
    "### Definição do cliente FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af99d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientFL(fl.client.NumPyClient):\n",
    "    def get_parameters(self):\n",
    "        return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(net.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        train(net, trainloader, epochs=1)\n",
    "        return self.get_parameters(), len(trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = test(net, testloader)\n",
    "        return float(loss), len(testloader), {\"accuracy\":float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a04d0332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2021-07-28 16:13:32,937 | connection.py:36 | ChannelConnectivity.IDLE\n",
      "INFO flower 2021-07-28 16:13:32,940 | app.py:61 | Opened (insecure) gRPC connection\n",
      "DEBUG flower 2021-07-28 16:13:32,941 | connection.py:36 | ChannelConnectivity.TRANSIENT_FAILURE\n",
      "DEBUG flower 2021-07-28 16:13:33,146 | connection.py:68 | Insecure gRPC channel closed\n"
     ]
    },
    {
     "ename": "_MultiThreadedRendezvous",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses\"\n\tdebug_error_string = \"{\"created\":\"@1627499612.939922600\",\"description\":\"Failed to pick subchannel\",\"file\":\"src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3008,\"referenced_errors\":[{\"created\":\"@1627499612.939919500\",\"description\":\"failed to connect to all addresses\",\"file\":\"src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":397,\"grpc_status\":14}]}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_133/4103136700.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_numpy_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[::]:8080\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClientFL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/project_cybersecurity/env/lib/python3.8/site-packages/flwr/client/app.py\u001b[0m in \u001b[0;36mstart_numpy_client\u001b[0;34m(server_address, client, grpc_max_message_length)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# Start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     start_client(\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mserver_address\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflower_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project_cybersecurity/env/lib/python3.8/site-packages/flwr/client/app.py\u001b[0m in \u001b[0;36mstart_client\u001b[0;34m(server_address, client, grpc_max_message_length)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mserver_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreceive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 client_message, sleep_duration, keep_going = handle(\n\u001b[1;32m     66\u001b[0m                     \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project_cybersecurity/env/lib/python3.8/site-packages/flwr/client/grpc_client/connection.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mserver_message_iterator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mServerMessage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mreceive\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServerMessage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_message_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0msend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mClientMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project_cybersecurity/env/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project_cybersecurity/env/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m_response_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses\"\n\tdebug_error_string = \"{\"created\":\"@1627499612.939922600\",\"description\":\"Failed to pick subchannel\",\"file\":\"src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3008,\"referenced_errors\":[{\"created\":\"@1627499612.939919500\",\"description\":\"failed to connect to all addresses\",\"file\":\"src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":397,\"grpc_status\":14}]}\"\n>"
     ]
    }
   ],
   "source": [
    "fl.client.start_numpy_client(\"[::]:8080\", client = ClientFL())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
